original link:http://blog.csdn.net/wuzhekai1985/article/details/6625434

问题描述：从海量数据日志中，提取出某日访问次数最多的那个IP。
        思路：对于海量数据的处理，主要采取的策略就是分而治之，即缩减问题的规模，将一个大的问题划分成若干等价的小问题。然后解决这些小问题，最后将获得的小问题解综合起来，得出原问题的解。用到比较多的技术主要有散列、位图、堆、trie树、mapreduce、K路归并（败者树）等。其中散列用的尤为多。
         对于本问题，假定某日访问的IP地址已经从数据日志中提取出来，存放在一个大的二进制文件中。下面的工作主要是找目标IP――文件中出现次数最多的那个IP。这个文件很大，内存无法完全放下，内排序的方法行不通。可以采取如下措施：
        （1）利用散列函数，将大文件中的IP地址散列到若干个文件中。相同的IP地址肯定在同一个文件中。
        （2）处理每个小文件，找到该文件中出现次数最多的那个IP，记录下IP地址和出现次数。可以用hash_map，IP地址为键值、出现次数为数值。
        （3）将第（2）步中找到的IP地址及出现次数综合起来，找到这些IP地址中出现次数最多的那个IP。
         简单实现：接下来给出一种简单的实现，效率比较低。测试中，从一个含4亿个IP地址的文件中提取目标IP，一共用了52分钟。其中大量的时间用于文件的读写，约为30分钟。另外有7分钟用于产生含4亿个随机数的文件。真正用于计算的时间为15分钟。由于C++标准STL中没有hash_map，因此该用map实现第（2）步，如果改用hash_map，应该能减少部分计算的时间。
        另外，如果设置读写缓冲区，经过测试，缓冲区为128字节时，读写文件的时间从原来的30分钟减为25分钟左右。进一步增大缓冲区大小，提升的速度比非常小，待求解。这里设置缓冲区不是指这种方式：
char buffer[1024]; 
streambuf * ptrbuf = outFile.rdbuf(); 
 ptrbuf-> pubsetbuf(buffer,1024); 
而是定义一个整形数组，每次读写时，读写一块数据而不是一个整数。
单个读写   outFile.write((char*)&x,sizeof(unsigned));
块读写       outFile.write((char *)buffer,BUFFER_SIZE*sizeof(unsigned));
